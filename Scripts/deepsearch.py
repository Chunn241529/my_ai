
from duckduckgo_search import DDGS
from bs4 import BeautifulSoup

import requests
from rich.markdown import Markdown



# import scripts
from commands import *
from file import *
from image import *
from generate import *

# Kh·ªüi t·∫°o console t·ª´ Rich
console = Console()
history_analys = []


# C√°c h√†m t·ª´ search.py
def search_web(query, max_results=2):
    results = []
    with DDGS() as ddgs:
        for r in ddgs.text(query, max_results=max_results):
            results.append({
                'title': r['title'],
                'url': r['href'],
                'snippet': r['body']
            })
    return results

def extract_content(url):
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        paragraphs = soup.find_all('p')
        content = " ".join([p.get_text() for p in paragraphs])
        return content[:12000]
    except Exception as e:
        return f"Error fetching {url}: {str(e)}"


def extract_queries(text, history_queries=None):
    if history_queries is None:
        history_queries = set()
    # N·∫øu text kh√¥ng h·ªó tr·ª£ split(), nghƒ©a l√† n√≥ kh√¥ng ph·∫£i l√† chu·ªói, ta s·∫Ω ti√™u th·ª• n√≥
    try:
        lines = text.split('\n')
    except AttributeError:
        # N·∫øu text l√† generator, chuy·ªÉn n√≥ th√†nh chu·ªói
        text = ''.join(text)
        lines = text.split('\n')

    queries = set()
    in_query_section = False

    for i, line in enumerate(lines):
        line_clean = line.strip().lower()
        if line_clean.startswith('ƒë·ªÅ xu·∫•t truy v·∫•n:') or line_clean.startswith('**ƒë·ªÅ xu·∫•t truy v·∫•n:**'):
            in_query_section = True
        elif in_query_section and (not line.strip() or not line.strip().startswith('*')):
            in_query_section = False

        if in_query_section:
            # N·∫øu d√≤ng hi·ªán t·∫°i kh√¥ng b·∫Øt ƒë·∫ßu b·∫±ng '*' nh∆∞ng c√≥ ch·ª©a 'ƒê·ªÅ xu·∫•t truy v·∫•n:'
            if i + 1 < len(lines) and not lines[i].strip().startswith('*') and lines[i].strip().startswith('ƒê·ªÅ xu·∫•t truy v·∫•n:'):
                next_line = lines[i + 1].strip()
                if next_line and not next_line.startswith('Truy v·∫•n t·ª´') and not next_line.startswith('ƒê√°nh gi√°:'):
                    clean_query = next_line.strip('"').strip('*').strip()
                    if clean_query and clean_query not in history_queries:
                        queries.add(clean_query)
            # N·∫øu d√≤ng hi·ªán t·∫°i b·∫Øt ƒë·∫ßu b·∫±ng '*' th√¨ tr√≠ch xu·∫•t ph·∫ßn sau d·∫•u *
            elif line.strip().startswith('*'):
                clean_query = line.strip()[1:].strip().strip('"').strip()
                if clean_query and clean_query not in history_queries:
                    queries.add(clean_query)

    return list(queries)[:1]


def deepsearch(initial_query, max_iterations=3):
    current_queries = []
    accumulated_context = ""
    all_answers = {}
    all_data = ""
    history_queries = set([initial_query])
    history_keywords = set()
    keywords = generate_keywords(initial_query, history_keywords=history_keywords)
    history_keywords.update(keywords)
    iteration = 0

    ### ph√¢n t√≠ch c√¢u h·ªèi
    analys_question_stream = analys_question(initial_query)
    full_analys_question=""
    for part in analys_question_stream:
        if part is not None:
            full_analys_question += part
    console.print((full_analys_question), soft_wrap=True)
    history_analys.append(full_analys_question)
    ###

    ### ph√¢n t√≠ch t√¨m ki·∫øm t·∫°o c√¢u truy v·∫•n
    analys_prompt_stream = analys_prompt(history_analys)
    full_analys_prompt=""
    for part in analys_prompt_stream:
        if part is not None:
            full_analys_prompt += part
    current_queries.append(full_analys_prompt)
    ###

    while iteration < max_iterations and current_queries:
        current_query = current_queries.pop(0)
        
        console.print("\n")
        console.print(f"[cyan]T√¨m ki·∫øm: {current_query} üîç[/cyan]")
        console.print("\n")

        search_results = search_web(current_query)
        if not search_results:
            all_answers[current_query] = "Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan."
            console.print(f"  [red]K·∫øt qu·∫£: Kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan. üòï[/red]")
            continue


        new_query_found = False

        # Duy·ªát qua t·ª´ng k·∫øt qu·∫£ t√¨m ki·∫øm
        for result in search_results:
            content = extract_content(result['url'])
            if "Error" not in content:
                console.print(f" [cyan]T√¨m ki·∫øm trong {result['url']}üîç\n[/cyan]")
                analysis = process_link(initial_query, result['url'], content, keywords)
                
                final_analysis = ""
                for part in analysis:
                    if part is not None:
                        final_analysis += part

                console.print(f"[magenta]Ph√¢n t√≠ch: {final_analysis}\n[/magenta]", soft_wrap=True)
                all_answers[current_query] = final_analysis

                all_data += f"{result['url']}: {final_analysis}\n"
                
                # Tr√≠ch xu·∫•t new_query t·ª´ n·ªôi dung ph√¢n t√≠ch
                new_queries = extract_queries(analysis, history_queries)
                if new_queries:
                    for query in new_queries:
                        if query not in history_queries:
                            current_queries.append(query)
                            history_queries.add(query)
                            console.print(f"Th√™m truy v·∫•n m·ªõi: {query}")
                            new_query_found = True
                    if new_query_found:
                        break

            accumulated_context += f"\nNgu·ªìn: {result['url']}\n{content}\n"

        
        ##old
        # for result in search_results:
        #     content = extract_content(result['url'])
        #     accumulated_context += f"\nNgu·ªìn: {result['url']}\n{content}\n"


        # Thu th·∫≠p to√†n b·ªô ph·∫£n h·ªìi t·ª´ reason_with_ollama
        answer_stream = reason_with_ollama(initial_query, accumulated_context)
        full_answer = ""
        for part in answer_stream:
            if part is not None:
                full_answer += part
        all_answers[current_query] = full_answer
        console.print(Markdown(full_answer), soft_wrap=True, end="")

        new_queries_from_reasoning = extract_queries(full_answer)

        # Thu th·∫≠p to√†n b·ªô ph·∫£n h·ªìi t·ª´ evaluate_answer
        evaluation_stream = evaluate_answer(initial_query, full_answer)
        full_evaluation = ""
        for part in evaluation_stream:
            if part is not None:
                full_evaluation += part
        console.print(f"[magenta]ƒê√°nh gi√°: {full_evaluation}[/magenta]")
        
        if "ƒë√£ ƒë·ªß" in full_evaluation.lower():
            console.print("[bold green]Th√¥ng tin ƒë√£ ƒë·ªß, kh√¥ng c·∫ßn t√¨m th√™m! üéâ[/bold green]")
            break
        elif "ch∆∞a ƒë·ªß" in full_evaluation.lower():
            new_queries_from_evaluation = extract_queries(full_evaluation)
            # console.print(f"  [blue]Truy v·∫•n t·ª´ ƒë√°nh gi√°: {new_queries_from_evaluation} üîÑ[/blue]")  # ·∫®n d√≤ng n√†y
            relevant_query = new_queries_from_evaluation[0] if new_queries_from_evaluation else (new_queries_from_reasoning[0] if new_queries_from_reasoning else None)
            if relevant_query and relevant_query not in current_queries and relevant_query not in all_answers:
                current_queries.append(relevant_query)
            else:
                console.print("[yellow]Kh√¥ng c√≥ truy v·∫•n m·ªõi ph√π h·ª£p ƒë·ªÉ ti·∫øp t·ª•c. ü§î[/yellow]")
            iteration += 1
        else:
            console.print(f"[red]ƒê√°nh gi√° kh√¥ng r√µ r√†ng: {full_evaluation} ‚ùì[/red]")
            new_queries_from_evaluation = extract_queries(full_evaluation)
            relevant_query = new_queries_from_evaluation[0] if new_queries_from_evaluation else (new_queries_from_reasoning[0] if new_queries_from_reasoning else None)
            if relevant_query and relevant_query not in current_queries and relevant_query not in all_answers:
                current_queries.append(relevant_query)
            else:
                current_queries.append(current_query)
            iteration += 1

    if iteration >= max_iterations:
        console.print(f"\n[bold red]ƒê√£ ƒë·∫°t gi·ªõi h·∫°n {max_iterations} l·∫ßn t√¨m ki·∫øm. ‚è≥[/bold red]")
    else:
        console.print("\n[bold green]ƒê√£ ho√†n th√†nh t√¨m ki·∫øm! üåü[/bold green]")
    
    summary_stream = summarize_answers(initial_query, all_answers)
    final_answer = ""
    for part in summary_stream:
        if part is not None:
            final_answer += part
    return f"\n{final_answer}"


# #H√†m test 
# query = "Model text to image n√†o ph√π h·ª£p v·ªõi card ƒë·ªì h·ªça 4060 8gb"
# console.print(deepsearch(query))