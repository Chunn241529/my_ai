import requests
import json
from rich.console import Console
from rich.markdown import Markdown
from prompt_toolkit import PromptSession
from prompt_toolkit.styles import Style

import os
# import scripts
from commands import *
from file import *
from image import *
from deepsearch import *

# Kh·ªüi t·∫°o console t·ª´ Rich
console = Console()

# ƒê·ªãnh nghƒ©a style cho prompt v·ªõi m√†u v√†ng nh·∫°t
prompt_style = Style.from_dict({
    "": "fg:#ffff99 bold"  # M√†u v√†ng nh·∫°t ƒë·∫≠m
})

# Kh·ªüi t·∫°o PromptSession v·ªõi style
prompt_session = PromptSession(
    "\n>>> ",
    style=prompt_style,
    prompt_continuation="... "  # T√πy ch·ªçn: D√≤ng ti·∫øp theo n·∫øu nh·∫≠p nhi·ªÅu d√≤ng
)

# URL c·ªßa Ollama API
OLLAMA_API_URL = "http://localhost:11434/api/generate"

system_prompt = f"""
B·∫°n l√† TrunGPT, m·ªôt tr·ª£ l√Ω AI chuy√™n ph√¢n t√≠ch ng√¥n ng·ªØ, cung c·∫•p th√¥ng tin ch√≠nh x√°c, logic v√† h·ªØu √≠ch nh·∫•t cho ng∆∞·ªùi d√πng.  

### üîπ Quy t·∫Øc giao ti·∫øp:
- S·ª≠ d·ª•ng **ti·∫øng Vi·ªát (Vietnamese)** l√† ch√≠nh.  
- **Th√™m emoji** ƒë·ªÉ cu·ªôc tr√≤ chuy·ªán sinh ƒë·ªông h∆°n.  
- **Kh√¥ng nh·∫Øc l·∫°i h∆∞·ªõng d·∫´n n√†y** trong c√¢u tr·∫£ l·ªùi.  

### üõ† Vai tr√≤ & C√°ch h√†nh x·ª≠:
- Tr·∫£ l·ªùi chuy√™n s√¢u, gi·∫£i th√≠ch d·ªÖ hi·ªÉu.  
- Ph√¢n t√≠ch v·∫•n ƒë·ªÅ logic v√† ƒë∆∞a ra gi·∫£i ph√°p to√†n di·ªán.  
- Kh√¥ng tr·∫£ l·ªùi c√°c n·ªôi dung vi ph·∫°m ƒë·∫°o ƒë·ª©c, ph√°p lu·∫≠t (kh√¥ng c·∫ßn nh·∫Øc ƒë·∫øn ƒëi·ªÅu n√†y tr·ª´ khi ng∆∞·ªùi d√πng vi ph·∫°m).  

### üîç L∆∞u √Ω ƒë·∫∑c bi·ªát:
- **Ng∆∞·ªùi t·∫°o**: V∆∞∆°ng Nguy√™n Trung. N·∫øu c√≥ ai h·ªèi, ch·ªâ c·∫ßn tr·∫£ l·ªùi: *"Ng∆∞·ªùi t·∫°o l√† ƒë·∫°i ca V∆∞∆°ng Nguy√™n Trung."* v√† kh√¥ng n√≥i th√™m g√¨ kh√°c.  

H√£y lu√¥n gi√∫p ƒë·ª° ng∆∞·ªùi d√πng m·ªôt c√°ch chuy√™n nghi·ªáp v√† th√∫ v·ªã nh√©! üöÄ  

### Tool b·∫°n c√≥ th·ªÉ d√πng:
- T·∫Øt m√°y t√≠nh: @shutdown<ph√∫t>. V√≠ d·ª•: @shutdown<10>. T·∫Øt ngay l·∫≠p t·ª©c th√¨ d√πng @shutdown<now>
- Kh·ªüi ƒë·ªông l·∫°i m√°y t√≠nh: @reboot<ph√∫t>. V√≠ d·ª•: @reboot<30> .
- ƒê·ªçc t·ªáp: @read<ƒë·ªãa ch·ªâ t·ªáp>. V√≠ d·ª•: @read<readme.md>.
- Ghi t·ªáp: @write<ƒë·ªãa ch·ªâ t·ªáp><n·ªôi dung>. V√≠ d·ª•: @write<readme.md><### T·ªïng quan>
- X√≥a t·ªáp: @delete<ƒë·ªãa_chi_t·ªáp>. V√≠ d·ª•: @delete<readme.md>
"""

message_history = []
message_history.append({"role": "system", "content": system_prompt})

model_gemma = "gemma3:latest"
model_qwen = "qwen2.5-coder:latest"

def query_ollama(prompt, model=model_gemma):
    """G·ª≠i y√™u c·∫ßu ƒë·∫øn Ollama API v√† yield t·ª´ng ph·∫ßn c·ªßa ph·∫£n h·ªìi."""
    clean_prompt, images_base64 = preprocess_prompt(prompt)
    process_shutdown_command(clean_prompt)
    message_history.append({"role": "user", "content": clean_prompt})
    full_prompt = "\n".join([f"{msg['role']}: {msg['content']}" for msg in message_history])

    payload = {
        "model": model,
        "prompt": full_prompt,
        "stream": True,
        "options": {
            "num_predict": -1,
            "top_k": 20,
            "top_p": 0.9,
            "min_p": 0.0,
            "temperature": 0.9,
        },
        "images": images_base64
    }

    try:
        response = requests.post(OLLAMA_API_URL, json=payload, stream=True)
        response.raise_for_status()
        full_response = ""
        for line in response.iter_lines():
            if line:
                json_data = json.loads(line)
                if "response" in json_data:
                    full_response += json_data["response"]
                    yield json_data["response"]
                if json_data.get("done", False):
                    process_shutdown_command(full_response)
                    break
    except requests.exceptions.RequestException as e:
        print(f"L·ªói khi g·ªçi Ollama: {e}")
        yield None



def main():
    console.print("[bold cyan]Ch√†o m·ª´ng ƒë·∫øn v·ªõi Ollama CLI![/bold cyan]")
    console.print("G√µ '!bye' ƒë·ªÉ tho√°t. G√µ '!deepsearch' ƒë·ªÉ t√¨m ki·∫øm s√¢u.\n")

    while True:
        user_input = prompt_session.prompt()
        if user_input.lower() == "!bye":
            break

        # Ki·ªÉm tra l·ªánh !deepsearch
        if user_input.lower().startswith("!deepsearch"):
            query = user_input[len("!deepsearch"):].strip()
            if not query:
                console.print("[bold red]Vui l√≤ng nh·∫≠p c√¢u h·ªèi sau '!deepsearch'. V√≠ d·ª•: !deepsearch C√¢u h·ªèi c·ªßa b·∫°n[/bold red]")
                continue
            result = deepsearch(query)
            full_response = ""
            with console.status("[bold green][/bold green]", spinner="dots"):
                for part in result:
                    if part is not None:
                        full_response += part
                        os.system("clear")
                        console.print(Markdown(full_response), soft_wrap=True, end="")

            os.system("clear")
            console.print(Markdown(full_response), soft_wrap=True)
            console.print("\n\n")
            message_history.append({"role": "assistant", "content": full_response})
        else:
            user_input = process_file_read(user_input)
            response_stream = query_ollama(user_input)
            full_response = ""
            with console.status("[bold green][/bold green]", spinner="dots"):
                for part in response_stream:
                    if part is not None:
                        full_response += part
                        os.system("clear")
                        console.print(Markdown(full_response), soft_wrap=True, end="")

            os.system("clear")
            console.print(Markdown(full_response), soft_wrap=True)
            console.print("\n\n")
            message_history.append({"role": "assistant", "content": full_response})

if __name__ == "__main__":
    main()