from duckduckgo_search import DDGS
from bs4 import BeautifulSoup
import requests
from rich.console import Console
from rich.markdown import Markdown
from rich.live import Live
import random
from typing import List, Set, Dict

# Gi·∫£ ƒë·ªãnh c√°c module n√†y ƒë√£ ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a
from functions.subfuncs.commands import *
from functions.subfuncs.file import *
from functions.subfuncs.generate import *

console = Console()


class DeepSearch:
    # random number

    # def random_number(self, min_val: int, max_val: int) -> int:
    #     """T·∫°o s·ªë ng·∫´u nhi√™n trong kho·∫£ng min_val ƒë·∫øn max_val."""
    #     return random.randint(min_val, max_val)

    def __init__(
        self,
        initial_query: str,
        max_iterations: int = 4,
        max_results: int = 10,
    ):
        """
        Kh·ªüi t·∫°o ƒë·ªëi t∆∞·ª£ng DeepSearch v·ªõi c√¢u h·ªèi ban ƒë·∫ßu v√† c√°c tham s·ªë c·∫•u h√¨nh.

        Args:
            initial_query (str): C√¢u h·ªèi/truy v·∫•n ban ƒë·∫ßu.
            max_iterations (int): S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa (m·∫∑c ƒë·ªãnh l√† 5).
            max_results (int): S·ªë k·∫øt qu·∫£ t√¨m ki·∫øm t·ªëi ƒëa m·ªói truy v·∫•n (m·∫∑c ƒë·ªãnh l√† 10).
        """
        self.initial_query = initial_query
        self.max_iterations = max_iterations
        self.max_results = max_results
        self.current_queries: List[str] = []
        self.accumulated_context: str = ""
        self.all_answers: Dict[str, str] = {}
        self.all_data: str = ""
        self.history_queries: Set[str] = {initial_query}
        self.history_keywords: Set[str] = set()
        self.processed_urls: Set[str] = set()
        self.history_analys: List[str] = []

        ### config live
        self.refresh_second = 10
        self.vertical_overflow = "ellipsis"  # "visible"

    def search_web(self, query: str) -> List[Dict[str, str]]:
        """T√¨m ki·∫øm tr√™n web b·∫±ng DuckDuckGo v√† tr·∫£ v·ªÅ danh s√°ch k·∫øt qu·∫£."""
        results = []
        with DDGS() as ddgs:
            for r in ddgs.text(query, max_results=self.max_results):
                results.append(
                    {"title": r["title"], "url": r["href"], "snippet": r["body"]}
                )
        return results

    def extract_content(self, url: str, snippet: str = "") -> str:
        """Tr√≠ch xu·∫•t n·ªôi dung t·ª´ URL, bao g·ªìm ƒëo·∫°n tr√≠ch v√† vƒÉn b·∫£n t·ª´ c√°c th·∫ª HTML."""
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, "html.parser")
            tags_to_extract = ["p", "h1", "h2", "h3", "a", "span", "table"]
            content_parts = [
                tag.get_text(strip=True)
                for tag in soup.find_all(tags_to_extract)
                if tag.get_text(strip=True)
            ]
            content = f"Snippet: {snippet}\n" + "\n".join(content_parts)
            return content
        except requests.RequestException as e:
            return f"Error fetching {url}: {str(e)}"

    def extract_hrefs(self, url: str) -> List[str]:
        """Tr√≠ch xu·∫•t t·∫•t c·∫£ li√™n k·∫øt (href) t·ª´ m·ªôt URL."""
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            soup = BeautifulSoup(response.text, "html.parser")
            href_list = [tag["href"] for tag in soup.find_all("a", href=True)]
            return href_list
        except requests.RequestException as e:
            return [f"Error fetching {url}: {str(e)}"]

    def extract_queries(self, text):
        """Tr√≠ch xu·∫•t c√°c truy v·∫•n t·ª´ vƒÉn b·∫£n."""
        lines = text.splitlines()
        queries = [line.strip() for line in lines if line.strip() and line != "NOT YET"]
        return queries[:4]  # Gi·ªõi h·∫°n t·ªëi ƒëa 4 truy v·∫•n

    def generate_keywords_and_analyze_question(self):
        """T·∫°o t·ª´ kh√≥a v√† ph√¢n t√≠ch c√¢u h·ªèi ban ƒë·∫ßu."""
        keywords_stream = generate_keywords(self.initial_query)
        full_keywords = ""
        for part in keywords_stream:
            if part is not None:
                full_keywords += part

        # L√†m s·∫°ch v√† tr√≠ch xu·∫•t t·ª´ kh√≥a t·ª´ ƒë·ªãnh d·∫°ng danh s√°ch
        keywords = []
        for line in full_keywords.splitlines():
            line = line.strip()
            if line.startswith("*"):  # Ch·ªâ l·∫•y d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng *
                keyword = (
                    line.strip("*").strip().strip('"').strip()
                )  # Lo·∫°i b·ªè *, ", v√† kho·∫£ng tr·∫Øng th·ª´a
                if keyword:  # Ch·ªâ th√™m n·∫øu t·ª´ kh√≥a kh√¥ng r·ªóng
                    keywords.append(keyword)

        self.history_keywords.update(keywords)  # C·∫≠p nh·∫≠t set v·ªõi t·ª´ kh√≥a ƒë√£ l√†m s·∫°ch
        # console.print(f"[red][DEBUG]{self.history_keywords}[/red]")

        with Live(
            Markdown("ƒêang ph√¢n t√≠ch c√¢u h·ªèi... üñêÔ∏è"),
            refresh_per_second=self.refresh_second,
            console=console,
            vertical_overflow=self.vertical_overflow,
        ) as live:
            analysis_stream = analys_question(self.initial_query, self.history_keywords)
            full_analysis = ""

            for part in analysis_stream:
                if part is not None:
                    full_analysis += part
                    clean_full = (
                        full_analysis.replace("<|begin_of_thought|>", "")
                        .replace("<|end_of_thought|>", "")
                        .replace("<|begin_of_solution|>", "")
                        .replace("<|end_of_solution|>", "")
                        # full_analysis.replace("<think>", "")
                        # .replace("</think>", "")
                    )
                    live.update(Markdown(f"\n{clean_full}"))

        # console.print(Markdown(full_analysis), soft_wrap=True, end="")

        if "Kh√≥ nha bro" in clean_full:
            self.all_answers.clear()
            better_question_stream = better_question(self.initial_query)
            new_question = ""
            with Live(
                Markdown("Ch·ªù x√≠u...üñêÔ∏è"),
                refresh_per_second=self.refresh_second,
                console=console,
                vertical_overflow=self.vertical_overflow,
            ) as live:
                for part in better_question_stream:
                    if part is not None:
                        new_question += part
                        live.update(Markdown(f"\n{new_question}"))
            clean_full = new_question

        self.history_analys.append(clean_full)

    def analyze_prompt(self):
        """Ph√¢n t√≠ch g·ª£i √Ω ƒë·ªÉ t·∫°o danh s√°ch truy v·∫•n ban ƒë·∫ßu."""
        analysis_stream = analys_prompt(
            self.history_analys
        )  # D√πng initial_query thay v√¨ history_analys
        full_analysis = ""
        for part in analysis_stream:
            if part is not None:
                full_analysis += part

        clean_full_analysis = (
            full_analysis.replace("1. ", "")
            .replace("2. ", "")
            .replace("3. ", "")
            .replace("4. ", "")
        )
        # T√°ch c√°c truy v·∫•n t·ª´ full_analysis (m·ªói truy v·∫•n tr√™n m·ªôt d√≤ng)
        queries = [
            q.strip('"').strip() for q in clean_full_analysis.splitlines() if q.strip()
        ]
        for query in queries:
            if query and query not in self.history_queries:
                self.current_queries.append(query)
                self.history_queries.add(query)

    def process_single_result(self, result: Dict[str, str]) -> bool:
        """X·ª≠ l√Ω m·ªôt k·∫øt qu·∫£ t√¨m ki·∫øm v√† tr·∫£ v·ªÅ li·ªáu n√≥ c√≥ ƒë·ªß th√¥ng tin kh√¥ng. Tr·∫£ v·ªÅ False t·ªëi ƒëa 3 l·∫ßn."""
        if not hasattr(self, "false_count"):
            self.false_count = 0

        url = result["url"]
        if url in self.processed_urls:
            if self.false_count < 2:
                self.false_count += 1
                return False
            return True

        content = self.extract_content(url, result["snippet"])
        if "Error" in content:
            if self.false_count < 2:
                self.false_count += 1
                return False
            return True
        console.print("[bold yellow]\nT√¨m ki·∫øm th√¥ng tin: \n[/bold yellow]")
        final_analysis = ""
        with Live(
            Markdown(f"\nT√¨m ki·∫øm trong [{result['title']}]({url})"),
            refresh_per_second=self.refresh_second,
            console=console,
            vertical_overflow=self.vertical_overflow,
        ) as live:
            analysis_stream = process_link(
                self.initial_query, url, content, list(self.history_keywords)
            )
            for part in analysis_stream:
                if part is not None:
                    final_analysis += part
                    clean_final_analysis = (
                        final_analysis.replace("<|begin_of_thought|>", "")
                        .replace("<|end_of_thought|>", "")
                        .replace("<|begin_of_solution|>", "")
                        .replace("<|end_of_solution|>", "")
                        .replace("<|end|> ", "")
                    )
                    live.update(Markdown(f"\nT√¨m ki·∫øm trong [{result['title']}]({url})\n\n{clean_final_analysis}"))

        self.processed_urls.add(url)
        sufficiency_stream = sufficiency_prompt(
            query=self.initial_query,
            url=url,
            processed_urls=",".join(self.processed_urls),  # Chuy·ªÉn th√†nh chu·ªói
            final_analysis=clean_final_analysis,
        )
        sufficiency_result = ""
        for part in sufficiency_stream:
            if part is not None:
                sufficiency_result += part

        if "OK" in sufficiency_result.upper():
            self.all_answers[self.initial_query] = clean_final_analysis
            self.history_analys.append(f"Th√¥ng tin chu·∫©n: [{clean_final_analysis}]")
            self.all_data += f"{url}: {clean_final_analysis}\n"
            return True

        # L·∫•y danh s√°ch truy v·∫•n b·ªï sung t·ª´ sufficiency_result
        new_queries = [
            q.strip()
            for q in sufficiency_result.splitlines()
            if q.strip() and q != "NOT YET"
        ]
        for query in new_queries:
            if query and query not in self.history_queries:
                self.current_queries.append(query)
                self.history_queries.add(query)

        self.all_answers[self.initial_query] = clean_final_analysis
        self.history_analys.append(clean_final_analysis)
        self.all_data += f"{url}: {clean_final_analysis}\n"
        self.accumulated_context += f"\nNgu·ªìn: {url}\n{content}\n"

        if self.false_count < 2:
            self.false_count += 1
            return False
        return True

    def search_and_process(self):
        """Th·ª±c hi·ªán t√¨m ki·∫øm v√† x·ª≠ l√Ω k·∫øt qu·∫£ trong t·ªëi ƒëa max_iterations l·∫ßn."""
        iteration = 0
        while iteration < self.max_iterations and self.current_queries:
            current_query = self.current_queries.pop(0)
            current_query_cleaned = re.sub(r'[\'"]', "", current_query)
            current_query_cleaned = re.sub(
                r"[^\w\s+-=/*]", "", current_query_cleaned, flags=re.UNICODE
            )
            current_query_cleaned = current_query_cleaned.strip()
            console.print(f"[cyan]\nƒêang t√¨m ki·∫øm: {current_query_cleaned}[/cyan]")

            try:
                search_results = self.search_web(current_query_cleaned)
                console.print(
                    f"[yellow]T√¨m th·∫•y {len(search_results)} k·∫øt qu·∫£.[/yellow]"
                )
                if not search_results or any(
                    result.get("title", "").startswith("EOF")
                    for result in search_results
                ):
                    console.print(
                        "[red]Kh√¥ng t√¨m th·∫•y th√¥ng tin h·ªØu √≠ch. ƒêang kh·ªüi ƒë·ªông l·∫°i v·ªõi truy v·∫•n m·ªõi...[/red]"
                    )
                    self.generate_keywords_and_analyze_question()
                    self.analyze_prompt()
                    continue

                for result in search_results:
                    if self.process_single_result(result):
                        break

                evaluation_stream = evaluate_answer(
                    self.initial_query,
                    self.history_analys[-1],
                    self.processed_urls,  # Ch·ªâ d√πng ph√¢n t√≠ch cu·ªëi
                )
                full_evaluation = ""
                for part in evaluation_stream:
                    if part is not None:
                        full_evaluation += part
                console.print("\n")
                if "ƒë√£ ƒë·ªß" in full_evaluation.lower():
                    console.print("[bold cyan]\nSuy lu·∫≠n v·∫•n ƒë·ªÅ: \n[/bold cyan]")
                    full_reason = ""
                    with Live(
                        Markdown("\nƒêang suy lu·∫≠n..\n"),
                        refresh_per_second=self.refresh_second,
                        console=console,
                        vertical_overflow=self.vertical_overflow,
                    ) as live:
                        answer_stream = reason_with_ollama(
                            self.initial_query,
                            self.history_analys,
                        )
                        for part in answer_stream:
                            if part is not None:
                                full_reason += part
                                full_reason_answers = (
                                    full_reason.replace("<|begin_of_thought|>", "")
                                    .replace("<|end_of_thought|>", "")
                                    .replace("<|begin_of_solution|>", "")
                                    .replace("<|end_of_solution|>", "")
                                    .replace("|<|end_of_thought|", "")
                                )
                                live.update(Markdown(f"\n{full_reason_answers}"))

                    self.all_answers[current_query_cleaned] = full_reason_answers
                    self.history_analys.append(full_reason_answers)
                    break
                else:
                    new_queries = [
                        q.strip()
                        for q in full_evaluation.splitlines()
                        if q.strip() and "ƒë·ªÅ xu·∫•t" not in q.lower()
                    ]
                    for query in new_queries:
                        if query and query not in self.history_queries:
                            self.current_queries.append(query)
                            self.history_queries.add(query)

            except Exception as e:
                console.print(f"[red]ƒê√£ x·∫£y ra l·ªói: {str(e)}[/red]")
                break

            iteration += 1

    def summarize(self) -> str:
        """T·ªïng h·ª£p c√°c c√¢u tr·∫£ l·ªùi ƒë√£ thu th·∫≠p."""
        console.print("[bold cyan]\nK·∫øt lu·∫≠n: \n[/bold cyan]")
        with Live(
            Markdown("Ch·ªù x√≠u...üñêÔ∏è"),
            refresh_per_second=self.refresh_second,
            console=console,
            vertical_overflow=self.vertical_overflow,
        ) as live:
            summary_stream = summarize_answers(self.initial_query, self.history_analys)
            final_answer = ""

            for part in summary_stream:
                if part is not None:
                    final_answer += part
                    live.update(Markdown(f"\n{final_answer}"))

        return final_answer

    def run(self) -> str:
        """Ch·∫°y to√†n b·ªô qu√° tr√¨nh t√¨m ki·∫øm s√¢u v√† tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi cu·ªëi c√πng."""
        self.generate_keywords_and_analyze_question()
        self.analyze_prompt()
        self.search_and_process()
        final_answer = self.summarize()
        # X√≥a l·ªãch s·ª≠ ƒë·ªÉ gi·∫£i ph√≥ng b·ªô nh·ªõ
        self.history_analys.clear()
        self.history_queries.clear()
        self.history_keywords.clear()
        self.all_answers.clear()
        self.current_queries.clear()
        return f"\n{final_answer}"


# # V√≠ d·ª• s·ª≠ d·ª•ng
# if __name__ == "__main__":
#     query = "C·∫≠p nh·∫≠t t·ª´ v·ª±ng hot trend m·ªõi c·ªßa genz Vi·ªát Nam ƒë·∫ßu nƒÉm 2025"
#     deep_search = DeepSearch(query)
#     console.print(deep_search.run())
