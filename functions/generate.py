from duckduckgo_search import DDGS
import requests
import json
from rich.console import Console

# Import cÃ¡c script (giáº£ Ä‘á»‹nh Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a)
from commands import *
from file import *
from image import *
from generate import *

console = Console()

# URL cá»§a Ollama API
OLLAMA_API_URL = "http://localhost:11434/api/generate"

# Äá»‹nh nghÄ©a model
model_gemma = "gemma3:latest"
model_qwen = "qwen2.5-coder:latest"
model_reason= "smallthinker:latest"
model_curent = model_gemma

# System prompt (giá»¯ nguyÃªn nhÆ° trong mÃ£ gá»‘c)
system_prompt = """
Báº¡n lÃ  TrunGPT, má»™t trá»£ lÃ½ AI chuyÃªn phÃ¢n tÃ­ch ngÃ´n ngá»¯, cung cáº¥p thÃ´ng tin chÃ­nh xÃ¡c, logic vÃ  há»¯u Ã­ch nháº¥t cho ngÆ°á»i dÃ¹ng.

### ğŸ”¹ Quy táº¯c giao tiáº¿p:
- Sá»­ dá»¥ng **tiáº¿ng Viá»‡t (Vietnamese)** lÃ  chÃ­nh.
- **ThÃªm emoji** Ä‘á»ƒ cuá»™c trÃ² chuyá»‡n sinh Ä‘á»™ng hÆ¡n.
- **KhÃ´ng nháº¯c láº¡i hÆ°á»›ng dáº«n nÃ y** trong cÃ¢u tráº£ lá»i.

### ğŸ›  Vai trÃ² & CÃ¡ch hÃ nh xá»­:
- Tráº£ lá»i chuyÃªn sÃ¢u, giáº£i thÃ­ch dá»… hiá»ƒu.
- PhÃ¢n tÃ­ch váº¥n Ä‘á» logic vÃ  Ä‘Æ°a ra giáº£i phÃ¡p toÃ n diá»‡n.
- KhÃ´ng tráº£ lá»i cÃ¡c ná»™i dung vi pháº¡m Ä‘áº¡o Ä‘á»©c, phÃ¡p luáº­t (khÃ´ng cáº§n nháº¯c Ä‘áº¿n Ä‘iá»u nÃ y trá»« khi ngÆ°á»i dÃ¹ng vi pháº¡m).

### ğŸ” LÆ°u Ã½ Ä‘áº·c biá»‡t:
- **NgÆ°á»i táº¡o**: VÆ°Æ¡ng NguyÃªn Trung. Náº¿u cÃ³ ai há»i, chá»‰ cáº§n tráº£ lá»i: *"NgÆ°á»i táº¡o lÃ  Ä‘áº¡i ca VÆ°Æ¡ng NguyÃªn Trung."* vÃ  khÃ´ng nÃ³i thÃªm gÃ¬ khÃ¡c.

HÃ£y luÃ´n giÃºp Ä‘á»¡ ngÆ°á»i dÃ¹ng má»™t cÃ¡ch chuyÃªn nghiá»‡p vÃ  thÃº vá»‹ nhÃ©! ğŸš€

### Tool báº¡n cÃ³ thá»ƒ dÃ¹ng:
- Táº¯t mÃ¡y tÃ­nh: @shutdown<phÃºt>. VÃ­ dá»¥: táº¯t mÃ¡y trong vÃ²ng 10 phÃºt thÃ¬ dÃ¹ng: @shutdown<10>.
- Táº¯t ngay láº­p tá»©c thÃ¬ dÃ¹ng @shutdown<now>
- Äá»ƒ há»§y táº¯t mÃ¡y thÃ¬ dÃ¹ng @shutdown<-c>
- Khá»Ÿi Ä‘á»™ng láº¡i mÃ¡y tÃ­nh: @reboot<phÃºt>. VÃ­ dá»¥: @reboot<30>.
- Äá»c tá»‡p: @read<Ä‘á»‹a chá»‰ tá»‡p>. VÃ­ dá»¥: @read<readme.md>.
- Ghi tá»‡p: @write<Ä‘á»‹a chá»‰ tá»‡p><ná»™i dung>. VÃ­ dá»¥: @write<readme.md><### Tá»•ng quan>
- XÃ³a tá»‡p: @delete<Ä‘á»‹a_chi_tá»‡p>. VÃ­ dá»¥: @delete<readme.md>
"""

# Khá»Ÿi táº¡o lá»‹ch sá»­ tin nháº¯n
message_history = [{"role": "system", "content": system_prompt}]

def query_ollama(prompt, model=model_curent, num_predict=-1, temperature=1):
    """Gá»­i yÃªu cáº§u Ä‘áº¿n Ollama API vÃ  yield tá»«ng pháº§n cá»§a pháº£n há»“i."""
    clean_prompt, images_base64 = preprocess_prompt(prompt)
    process_shutdown_command(clean_prompt)
    message_history.append({"role": "user", "content": clean_prompt})
    full_prompt = "\n".join([f"{msg['role']}: {msg['content']}" for msg in message_history])

    payload = {
        "model": model,
        "prompt": full_prompt,
        "stream": True,
        "options": {
            "num_predict": num_predict,
            "temperature": temperature,
        },
        "images": images_base64
    }

    try:
        response = requests.post(OLLAMA_API_URL, json=payload, stream=True)
        response.raise_for_status()
        for line in response.iter_lines():
            if line:
                json_data = json.loads(line)
                if "response" in json_data:
                    yield json_data["response"]
                if json_data.get("done", False):
                    break
    except requests.RequestException as e:
        print(f"Lá»—i khi gá»i Ollama: {e}")
        yield None

def generate_keywords(query, model=model_curent):
    """Táº¡o tá»« khÃ³a liÃªn quan Ä‘áº¿n query vÃ  yield tá»«ng pháº§n cá»§a pháº£n há»“i."""
    prompt = f"""
        PhÃ¢n tÃ­ch cÃ¢u há»i: "{query}" vÃ  trÃ­ch xuáº¥t 2-5 tá»« khÃ³a chÃ­nh. CÃ¡c tá»« khÃ³a pháº£i thá»a mÃ£n:  
        1. LÃ  cÃ¡c cá»¥m tá»« hoáº·c tá»« quan trá»ng, pháº£n Ã¡nh Ä‘Ãºng Ã½ nghÄ©a cá»‘t lÃµi cá»§a cÃ¢u há»i.  
        2. Giá»¯ nguyÃªn ngÃ´n ngá»¯ cá»§a cÃ¢u há»i (tiáº¿ng Viá»‡t náº¿u cÃ¢u há»i báº±ng tiáº¿ng Viá»‡t).  
        3. KhÃ´ng thÃªm tá»« ngoÃ i ngá»¯ cáº£nh, chá»‰ láº¥y tá»« hoáº·c cá»¥m tá»« cÃ³ trong cÃ¢u há»i.  
        4. ÄÆ°á»£c trÃ¬nh bÃ y dÆ°á»›i dáº¡ng danh sÃ¡ch: * "tá»« khÃ³a 1" * "tá»« khÃ³a 2" * "tá»« khÃ³a 3" * "tá»« khÃ³a 4" * "tá»« khÃ³a 5" (náº¿u Ä‘á»§ 5 tá»« khÃ³a).  
        Chá»‰ tráº£ vá» danh sÃ¡ch tá»« khÃ³a, khÃ´ng thÃªm giáº£i thÃ­ch hay ná»™i dung khÃ¡c.
    """
    return query_ollama(prompt, model, num_predict=500, temperature=0.1)

def analys_question(query, keywords, model=model_curent):
    """PhÃ¢n tÃ­ch cÃ¢u há»i vÃ  yield tá»«ng pháº§n cá»§a pháº£n há»“i."""
    prompt = f"""
    XÃ©t cÃ¢u há»i: '{query}'.
    - Náº¿u cÃ¢u há»i khÃ´ng rÃµ rÃ ng, vÃ´ lÃ½, hoáº·c khÃ´ng thá»ƒ phÃ¢n tÃ­ch (vÃ­ dá»¥: "MÃ¹i cá»§a mÆ°a náº·ng bao nhiÃªu?"), chá»‰ cáº§n tráº£ vá» "KhÃ³ nha bro, [lÃ½ do ngáº¯n gá»n tá»± nhiÃªn]" vÃ  dá»«ng láº¡i.
    - Náº¿u cÃ¢u há»i cÃ³ thá»ƒ phÃ¢n tÃ­ch:
        Dá»±a trÃªn cÃ¡c tá»« khÃ³a chÃ­nh Ä‘Æ°á»£c cung cáº¥p: {', '.join(keywords)}, hÃ£y phÃ¢n tÃ­ch cÃ¢u há»i má»™t cÃ¡ch chi tiáº¿t vÃ  tá»± nhiÃªn. 
            - Xem xÃ©t Ã½ nghÄ©a cá»§a tá»«ng khÃ­a cáº¡nh trong ngá»¯ cáº£nh cÃ¢u há»i, vai trÃ² cá»§a chÃºng trong váº¥n Ä‘á» Ä‘Æ°á»£c Ä‘áº·t ra, vÃ  cÃ¡ch chÃºng liÃªn káº¿t vá»›i má»¥c tiÃªu cá»§a ngÆ°á»i dÃ¹ng (há» cÃ³ thá»ƒ muá»‘n thÃ´ng tin, giáº£i phÃ¡p, hay Ä‘iá»u gÃ¬ khÃ¡c). 
            - Sau Ä‘Ã³, xÃ¡c Ä‘á»‹nh má»¥c tiÃªu chÃ­nh cá»§a ngÆ°á»i dÃ¹ng (nhÆ° tÃ¬m hiá»ƒu, giáº£i quyáº¿t váº¥n Ä‘á», hoáº·c láº¥y vÃ­ dá»¥) vÃ  cÃ¡ch cÃ¢u há»i cÃ³ thá»ƒ Ä‘Æ°á»£c hiá»ƒu theo hÆ°á»›ng rÃµ rÃ ng hÆ¡n. 
            - Tráº£ lá»i má»™t cÃ¡ch Ä‘áº§y Ä‘á»§, khÃ´ng Ä‘á» cáº­p trá»±c tiáº¿p Ä‘áº¿n tá»« khÃ³a, chá»‰ táº­p trung vÃ o phÃ¢n tÃ­ch vÃ  káº¿t ná»‘i cÃ¡c Ã½ vá»›i Ã½ Ä‘á»‹nh cá»§a cÃ¢u há»i. 
    - Äáº£m báº£o pháº£n há»“i lÃ  má»™t Ä‘oáº¡n vÄƒn phÃ¢n tÃ­ch Ä‘áº§y Ä‘á»§, khÃ´ng liá»‡t kÃª tá»« khÃ³a, khÃ´ng cÃ³ pháº§n má»Ÿ Ä‘áº§u nhÆ° "To answer this: " hay tÆ°Æ¡ng tá»±, sá»­ dá»¥ng markdown.
    """
    return query_ollama(prompt, model, num_predict=4000, temperature=0.3)

def better_question(query, model=model_curent):
    """Cáº£i thiá»‡n cÃ¢u há»i vÃ  yield tá»«ng pháº§n cá»§a pháº£n há»“i."""
    better_prompt = f"""
        CÃ¢u há»i gá»‘c: '{query}'
        XÃ©t ká»¹ cÃ¢u há»i nÃ y: NÃ³ thiáº¿u gÃ¬ Ä‘á»ƒ rÃµ nghÄ©a hÆ¡n? Bá»• sung sao cho tá»± nhiÃªn, cá»¥ thá»ƒ vÃ  dá»… hiá»ƒu, nhÆ° cÃ¡ch nÃ³i chuyá»‡n vá»›i báº¡n. Viáº¿t láº¡i thÃ nh cÃ¢u há»i Ä‘áº§y Ä‘á»§, giá»¯ Ã½ chÃ­nh nhÆ°ng máº¡ch láº¡c hÆ¡n.
    """
    return query_ollama(better_prompt, model, num_predict=4000, temperature=0.3)

def analys_prompt(query, model=model_curent):
    """Táº¡o truy váº¥n tÃ¬m kiáº¿m tá»« query vÃ  yield tá»«ng pháº§n cá»§a pháº£n há»“i."""
    prompt = f"""
        Dá»±a trÃªn cÃ¢u há»i chÃ­nh '{query}', táº¡o má»™t truy váº¥n tÃ¬m kiáº¿m duy nháº¥t.
        Náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n Viá»‡t Nam, hÃ£y táº¡o truy váº¥n tÃ¬m kiáº¿m báº±ng tiáº¿ng Viá»‡t; náº¿u khÃ´ng, hÃ£y táº¡o báº±ng tiáº¿ng Anh.
        Chá»‰ tráº£ vá» truy váº¥n tÃ¬m kiáº¿m, khÃ´ng tráº£ vá» báº¥t ká»³ dá»¯ liá»‡u nÃ o khÃ¡c.
    """
    return query_ollama(prompt, model, num_predict=100, temperature=0.2)


def process_link(query, url, content, keywords, model=model_curent):
    """Xá»­ lÃ½ ná»™i dung tá»« URL vÃ  yield tá»«ng pháº§n cá»§a pháº£n há»“i."""
    prompt = f"""
        Ná»™i dung tá»« {url}:
        {content}
        Táº­p trung vÃ o cÃ¡c tá»« khÃ³a: {', '.join(keywords)}.
        HÃ£y tinh chá»‰nh sau Ä‘Ã³ trÃ­ch xuáº¥t thÃ´ng tin má»™t cÃ¡ch logic.
        Suy luáº­n, nghiÃªn cá»©u ná»™i dung vÃ  tráº£ lá»i cÃ¢u há»i chi tiáº¿t dá»±a trÃªn thÃ´ng tin cÃ³ sáºµn.
        Sau Ä‘Ã³ Ä‘Æ°a ra káº¿t luáº­n Ä‘áº§y Ä‘á»§ Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i {query}
        KhÃ´ng cÃ³ pháº§n má»Ÿ Ä‘áº§u nhÆ° "To answer this: " hay tÆ°Æ¡ng tá»±, sá»­ dá»¥ng markdown.
    """
    return query_ollama(prompt, model, num_predict=-1, temperature=0.9)

def reason_with_ollama(query, context, model=model_curent):
    """Suy luáº­n vÃ  tráº£ lá»i cÃ¢u há»i dá»±a trÃªn context vÃ  yield tá»«ng pháº§n cá»§a pháº£n há»“i."""
    prompt = f"""
        DÃ¹ng tiáº¿ng Viá»‡t Ä‘á»ƒ tráº£ lá»i.
        CÃ¢u há»i chÃ­nh: {query}
        ThÃ´ng tin: {context}
        HÃ£y reasoning vÃ  tráº£ lá»i trá»±c tiáº¿p cÃ¢u há»i chÃ­nh '{query}' dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p. Thá»±c hiá»‡n theo cÃ¡c bÆ°á»›c sau, nhÆ°ng khÃ´ng hiá»ƒn thá»‹ sá»‘ bÆ°á»›c hay tiÃªu Ä‘á» trong cÃ¢u tráº£ lá»i:
        - TÃ¬m cÃ¡c dá»¯ kiá»‡n quan trá»ng trong thÃ´ng tin, bao gá»“m cáº£ chi tiáº¿t cá»¥ thá»ƒ (sá»‘ liá»‡u, sá»± kiá»‡n) vÃ  Ã½ nghÄ©a ngáº§m hiá»ƒu náº¿u cÃ³.
        - Dá»±a trÃªn dá»¯ kiá»‡n, xÃ¢y dá»±ng láº­p luáº­n há»£p lÃ½ báº±ng cÃ¡ch liÃªn káº¿t cÃ¡c thÃ´ng tin vá»›i nhau; náº¿u thiáº¿u dá»¯ liá»‡u, Ä‘Æ°a ra suy Ä‘oÃ¡n cÃ³ cÆ¡ sá»Ÿ vÃ  giáº£i thÃ­ch; xem xÃ©t cÃ¡c kháº£ nÄƒng khÃ¡c nhau náº¿u phÃ¹ há»£p, rá»“i chá»n hÆ°á»›ng tráº£ lá»i tá»‘t nháº¥t.
        - Cuá»‘i cÃ¹ng, tráº£ lá»i ngáº¯n gá»n, rÃµ rÃ ng, Ä‘Ãºng trá»ng tÃ¢m cÃ¢u há»i, dá»±a hoÃ n toÃ n trÃªn láº­p luáº­n, sá»­ dá»¥ng markdown.
        Viáº¿t tá»± nhiÃªn, máº¡ch láº¡c nhÆ° má»™t Ä‘oáº¡n vÄƒn liá»n máº¡ch, chá»‰ dÃ¹ng thÃ´ng tin tá»« context, khÃ´ng thÃªm dá»¯ liá»‡u ngoÃ i, khÃ´ng cÃ³ pháº§n má»Ÿ Ä‘áº§u nhÆ° "To answer this: " hay tÆ°Æ¡ng tá»±.
    """
    return query_ollama(prompt, model, num_predict=4000, temperature=0.7)

def evaluate_answer(query, answer, processed_urls, model=model_curent):
    """ÄÃ¡nh giÃ¡ cÃ¢u tráº£ lá»i vÃ  yield tá»«ng pháº§n cá»§a pháº£n há»“i."""
    eval_prompt = f"""
        Danh sÃ¡ch URL Ä‘Ã£ phÃ¢n tÃ­ch: {processed_urls}
        Náº¿u URL nÃ y trÃ¹ng vá»›i báº¥t ká»³ URL nÃ o trong danh sÃ¡ch Ä‘Ã£ phÃ¢n tÃ­ch, tráº£ lá»i 'ChÆ°a Ä‘á»§' vÃ  khÃ´ng Ä‘Ã¡nh giÃ¡ thÃªm.
        HÃ£y Ä‘Ã¡nh giÃ¡ xem cÃ¢u tráº£ lá»i '{answer}' Ä‘Ã£ cung cáº¥p Ä‘áº§y Ä‘á»§ thÃ´ng tin Ä‘á»ƒ giáº£i quyáº¿t cÃ¢u há»i '{query}' chÆ°a.
        - 'Äáº§y Ä‘á»§' nghÄ©a lÃ  cÃ¢u tráº£ lá»i Ä‘Ã¡p á»©ng trá»±c tiáº¿p, rÃµ rÃ ng vÃ  khÃ´ng thiáº¿u khÃ­a cáº¡nh quan trá»ng nÃ o cá»§a cÃ¢u há»i.
        - 'ChÆ°a Ä‘á»§' nghÄ©a lÃ  cÃ²n thiáº¿u thÃ´ng tin cáº§n thiáº¿t hoáº·c khÃ´ng tráº£ lá»i Ä‘Ãºng trá»ng tÃ¢m.
        Tráº£ lá»i báº¯t Ä‘áº§u báº±ng 'ÄÃ£ Ä‘á»§' náº¿u thÃ´ng tin Ä‘áº§y Ä‘á»§, hoáº·c 'ChÆ°a Ä‘á»§' náº¿u thiáº¿u thÃ´ng tin cáº§n thiáº¿t.
        - Náº¿u 'ÄÃ£ Ä‘á»§', chá»‰ viáº¿t 'ÄÃ£ Ä‘á»§', khÃ´ng thÃªm gÃ¬ ná»¯a.
        - Náº¿u 'ChÆ°a Ä‘á»§', thÃªm pháº§n 'Äá» xuáº¥t truy váº¥n:' vá»›i CHá»ˆ 1 truy váº¥n cá»¥ thá»ƒ báº±ng tiáº¿ng Anh, ngáº¯n gá»n, dáº¡ng cá»¥m tá»« tÃ¬m kiáº¿m (khÃ´ng pháº£i cÃ¢u há»i), liÃªn quan trá»±c tiáº¿p Ä‘áº¿n cÃ¢u ban Ä‘áº§u, theo Ä‘á»‹nh dáº¡ng:
        Äá» xuáº¥t truy váº¥n:
        * \"tá»« khÃ³a hoáº·c cá»¥m tá»« tÃ¬m kiáº¿m cá»¥ thá»ƒ\"
        VÃ­ dá»¥: Náº¿u cÃ¢u ban Ä‘áº§u lÃ  'LÃ m sao Ä‘á»ƒ há»c tiáº¿ng Anh nhanh?' vÃ  cÃ¢u tráº£ lá»i lÃ  'Há»c tá»« vá»±ng má»—i ngÃ y', thÃ¬:
        ChÆ°a Ä‘á»§
        Äá» xuáº¥t truy váº¥n:
        * \"methods to learn English faster\"
        Äáº£m báº£o luÃ´n báº¯t Ä‘áº§u báº±ng 'ÄÃ£ Ä‘á»§' hoáº·c 'ChÆ°a Ä‘á»§', vÃ  truy váº¥n pháº£i lÃ  cá»¥m tá»« tÃ¬m kiáº¿m, khÃ´ng pháº£i cÃ¢u há»i.
    """
    return query_ollama(eval_prompt, model, num_predict=50, temperature=0.5)

def summarize_answers(query, all_answers, model=model_curent):
    """Tá»•ng há»£p cÃ¡c cÃ¢u tráº£ lá»i vÃ  yield tá»«ng pháº§n cá»§a pháº£n há»“i dÆ°á»›i dáº¡ng Markdown."""
    summary_prompt = f"""
        CÃ¢u há»i: '{query}'  
        ThÃ´ng tin thu tháº­p: {'\n'.join([f'- {a}' for a in all_answers])}  
        HÃ£y tráº£ lá»i cÃ¢u há»i '{query}' dá»±a trÃªn thÃ´ng tin thu tháº­p báº±ng cÃ¡ch:  
        1. **PhÃ¢n tÃ­ch chi tiáº¿t tá»«ng cÃ¢u tráº£ lá»i:** Má»—i Ã½ nÃ³i gÃ¬? LiÃªn quan Ä‘áº¿n cÃ¢u há»i nhÆ° tháº¿ nÃ o? Äi sÃ¢u vÃ o tá»«ng khÃ­a cáº¡nh, ká»ƒ cáº£ chi tiáº¿t nhá», dÃ¹ng *in nghiÃªng* cho cÃ¡c tá»« khÃ³a quan trá»ng vÃ  **in Ä‘áº­m** cho Ã½ chÃ­nh. Náº¿u Ã½ nÃ o khÃ´ng há»£p lá»‡ (vÃ´ nghÄ©a, láº¡c Ä‘á», mÃ¢u thuáº«n), loáº¡i bá» vÃ  giáº£i thÃ­ch rÃµ lÃ½ do trong má»™t Ä‘oáº¡n riÃªng vá»›i cÃº phÃ¡p `- LÃ½ do loáº¡i bá»: "..."`.  
        2. **Tá»•ng há»£p toÃ n bá»™ Ã½ há»£p lá»‡:** Gá»™p táº¥t cáº£ cÃ¡c Ã½ liÃªn quan thÃ nh má»™t cÃ¢u tráº£ lá»i cá»±c ká»³ chi tiáº¿t vÃ  Ä‘áº§y Ä‘á»§ dÆ°á»›i dáº¡ng Markdown, khÃ´ng bá» sÃ³t báº¥t ká»³ thÃ´ng tin nÃ o cÃ³ giÃ¡ trá»‹. Sá»­ dá»¥ng danh sÃ¡ch `-` hoáº·c sá»‘ `1.` khi liá»‡t kÃª, khÃ´ng ngáº¡i dÃ i dÃ²ng, má»Ÿ rá»™ng Ã½ Ä‘á»ƒ giáº£i thÃ­ch rÃµ rÃ ng, nhÆ°ng váº«n giá»¯ trá»ng tÃ¢m cÃ¢u há»i.  
        3. **Sáº¯p xáº¿p logic vÃ  cÃ³ cáº¥u trÃºc:** Sá»­ dá»¥ng thá»© tá»± há»£p lÃ½ (theo thá»i gian náº¿u lÃ  quy trÃ¬nh, má»©c Ä‘á»™ quan trá»ng náº¿u lÃ  Æ°u tiÃªn, hoáº·c chia theo chá»§ Ä‘á» vá»›i cÃ¡c tiÃªu Ä‘á» `##` náº¿u cÃ³ nhiá»u khÃ­a cáº¡nh), thÃªm cÃ¢u ná»‘i Ä‘á»ƒ liá»n máº¡ch.  
        4. **Viáº¿t tá»± nhiÃªn vÃ  sinh Ä‘á»™ng:** DÃ¹ng ngÃ´n ngá»¯ thÃ¢n thiá»‡n, trÃ´i cháº£y, nhÆ° ká»ƒ chuyá»‡n cho báº¡n, káº¿t há»£p Markdown Ä‘á»ƒ lÃ m ná»•i báº­t (vÃ­ dá»¥: *vÃ­ dá»¥ minh há»a*, **káº¿t luáº­n quan trá»ng**).  
        5. **Bá»• sung thÃ´ng tin má»Ÿ rá»™ng:** Náº¿u cÃ³ thá»ƒ, thÃªm thÃ´ng tin ngoÃ i dá»¯ liá»‡u cung cáº¥p (URL, tÃ i liá»‡u, vÃ­ dá»¥ thá»±c táº¿, suy luáº­n logic) trong má»™t pháº§n riÃªng. Táº­n dá»¥ng kiáº¿n thá»©c cá»§a báº¡n Ä‘á»ƒ lÃ m giÃ u cÃ¢u tráº£ lá»i.  
        Tráº£ vá» má»™t Ä‘oáº¡n vÄƒn dÃ i, cá»±c ká»³ chi tiáº¿t dÆ°á»›i dáº¡ng Markdown, bao quÃ¡t má»i khÃ­a cáº¡nh há»£p lá»‡ tá»« thÃ´ng tin thu tháº­p, khÃ´ng bá» sÃ³t báº¥t ká»³ Ã½ nÃ o cÃ³ giÃ¡ trá»‹. ToÃ n bá»™ ná»™i dung pháº£i Ä‘Æ°á»£c Ä‘á»‹nh dáº¡ng báº±ng cÃº phÃ¡p Markdown.
    """
    return query_ollama(summary_prompt, model, num_predict=-1, temperature=0.8)
